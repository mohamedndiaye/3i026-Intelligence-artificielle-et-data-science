{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "IA & Data science (3i026) -- 2018-2019\n",
    "--------\n",
    "*&copy; Equipe pédagogique: Manon Ansart, Vincent Guigue, Marie-Jeanne Lesot, Christophe Marsala, Olivier Schwander.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TD-TME03: Programmation du kernel perceptron\n",
    "\n",
    "Le but de ce TP est de terminer l'extension de l'algoritheme du perceptron à l'aide de noyaux, avant de commencer à étudier les données du projet."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=\"+1\" color=\"RED\">**[Q]**</font> **Indiquer dans la boîte ci-dessous vos noms et prénoms :**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leygonie Rebecca Laouer Walid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> **Renommer ce fichier ipython**\n",
    "\n",
    "Tout en haut de cette page, cliquer sur <tt>tme-04</tt> et rajouter à la suite de <tt>tme-04</tt> les noms des membres du binômes séparés par un tiret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">IMPORTANT: soumission de votre fichier final</font>\n",
    "\n",
    "**Nom à donner au fichier à poster** : *tme-04-Nom1_Nom2.ipynb* \n",
    "- *Nom1* et *Nom2* : noms des membres du binôme\n",
    "- ne pas compresser ou faire une archive: il faut rendre le fichier ipython tel quel, éventuellement, si vous avez d'autres fichiers vous les rendez séparément.\n",
    "\n",
    "**Echancier pour la soumission de votre compte-rendu:**\n",
    "- le compte-rendu d'une séance doit être remis obligatoirement <font color=\"RED\">** à la fin de la séance**</font>. C'est ce compte-rendu qui donne la note de base de la séance.\n",
    "- vous pouvez éventuellement compléter votre compte-rendu  pour obtenir des points bonus, dans ce cas, vous devez soumettre votre complément avant le début de la semaine suivante.\n",
    "\n",
    "** Sur la page Moodle de remise du travail <font color=\"RED\">ne pas oublier d'envoyer le compte rendu</font>** à la fin de la séance, la soumission de la version complémentaire post-séance se fera sur une page différente."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mise à jour de votre librairie IADS\n",
    "\n",
    "Comme lors de la séance précédente, vous devez utiliser les fonctions de la librairie IADS.\n",
    "\n",
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> **Ouvrir et compléter les fichiers Classifiers.py et utils.py**\n",
    "\n",
    "Rajouter dans la librairie les fonctions et classes et que vous avez écrites lors de la séance précédente. \n",
    "\n",
    "**Rappel**: dans un premier temps, vous devez écrire les classes et fonctions demandées dans le notebook de la séance de TDTME en cours. La séance suivante, vous rajouterez tout cela, une fois que vous l'aurez bien testé, dans vos fichiers de la librairie IADS.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "# La ligne suivante permet de préciser le chemin d'accès à la librairie iads\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "\n",
    "# Importation de la librairie iadsp = Kernel_Perceptron(2,0.001,100,1)\n",
    "import iads as iads\n",
    "\n",
    "# importation de LabeledSet\n",
    "from iads import LabeledSet as ls\n",
    "\n",
    "# importation de Classifiers\n",
    "from iads import Classifiers as cl\n",
    "\n",
    "# importation de utils\n",
    "from iads import utils as ut\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemple d'utilisation de LabeledSet\n",
    "\n",
    "une_base = ls.LabeledSet(2)        # définition d'une base pour contenir des exemples en 2D\n",
    "\n",
    "une_base.addExample([0, 1],1)   # ajout de l'exemple (0, 1) de classe +1\n",
    "une_base.addExample([2, 3],1)   # ajout de l'exemple (2, 3) de classe +1\n",
    "une_base.addExample([1, 2],-1)  # ajout de l'exemple (1, 2) de classe -1\n",
    "une_base.addExample([2, 2],-1)  # ajout de l'exemple (2, 2) de classe -1\n",
    "\n",
    "the_set=une_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Kernel Trick\n",
    "--------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons projeter (manuellement) les données 2D dans un espace de plus grande dimension. Voici un exemple de projection qui transforme un vecteur $(x_1,x_2)$ en un vecteur $(x_1,x_2,1)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 3, 1])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class KernelBias:\n",
    "    def transform(self,x):\n",
    "        y=np.asarray([x[0],x[1],1])\n",
    "        return y\n",
    "\n",
    "k=KernelBias()\n",
    "k.transform(the_set.getX(1))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Implémenter la classe ClassifierPerceptronKernel qui prend un Kernel en paramètre, et calcule le perceptron sur la version \"kernélisée\" des données. Tester ce perceptron sur le dataset 1 (2 gaussiennes) et le dataset XOR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "class ClassifierPerceptronKernel(cl.Classifier):\n",
    "    \n",
    "    def __init__(self,dimension_kernel,learning_rate,nb_Iterations,kernel):\n",
    "        \"\"\" Argument:\n",
    "                - intput_dimension (int) : dimension d'entrée des exemples\n",
    "                - learning_rate :\n",
    "            Hypothèse : input_dimension > 0\n",
    "        \"\"\"\n",
    "        self.dimension_kernel=dimension_kernel\n",
    "        self.n=learning_rate\n",
    "        self.nb_Iterations=nb_Iterations\n",
    "        self.kernel = kernel\n",
    "        self.w=np.random.randn(dimension_kernel)\n",
    "        \n",
    "        \n",
    "    def train(self, labeledSet):\n",
    "        self.labeledSet = labeledSet\n",
    "        i = 0 \n",
    "        while (i < self.nb_Iterations):\n",
    "            index_aleatoire = random.randint(0,labeledSet.size()-1)\n",
    "            if(labeledSet.getY(index_aleatoire)*self.predict(labeledSet.getX(index_aleatoire)) < 0 ):\n",
    "                    self.w = self.w+self.n*labeledSet.getY(index_aleatoire)*self.kernel.transform(labeledSet.getX(index_aleatoire))\n",
    "            i +=1\n",
    "    \n",
    "    def predict(self, x):\n",
    "        z = np.dot(self.kernel.transform(x), self.w)\n",
    "        if z > 0:\n",
    "            return +1\n",
    "        else:\n",
    "            return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (3,) and (2,) not aligned: 3 (dim 0) != 2 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-e3b3adb30594>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mtab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthe_set\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-a19d8f7a4bca>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, labeledSet)\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnb_Iterations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m             \u001b[0mindex_aleatoire\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabeledSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeledSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_aleatoire\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeledSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_aleatoire\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlabeledSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetY\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_aleatoire\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabeledSet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetX\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_aleatoire\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mi\u001b[0m \u001b[0;34m+=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-a19d8f7a4bca>\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mz\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (3,) and (2,) not aligned: 3 (dim 0) != 2 (dim 0)"
     ]
    }
   ],
   "source": [
    "tab=[]\n",
    "p = ClassifierPerceptronKernel(2,0.0001,1,k)\n",
    "for k in range (20):\n",
    "    \n",
    "    p.train(the_set)\n",
    "    tab.append(p.accuracy(the_set))\n",
    "plt.plot(tab)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generer_exemple(mean=0):\n",
    "    \"\"\"Genere un exemple\"\"\"\n",
    "    mean = [mean, mean]\n",
    "    cov = [[1, 0], [0, 6]]\n",
    "    return np.random.multivariate_normal(mean, cov)\n",
    "\n",
    "def generer_exemples(nombre_exemples, mean=0):\n",
    "    \"\"\" Genere une liste de taille 'nombre_exemple' d'exemples \"\"\"\n",
    "    exemples = list()\n",
    "    for _ in range(nombre_exemples):\n",
    "        exemples.append(generer_exemple(mean))   \n",
    "    return exemples\n",
    "\n",
    "def ajouter_exemples_aleatoires(the_set, nombre_exemples, mean, labels):\n",
    "    \"\"\" Ajoute dans 'the_set' un total de 'nombre_exemples' exemples\n",
    "    associés aleatoirement à un label contenu dans 'labels'. \"\"\"\n",
    "    from random import choice\n",
    "    exemples = generer_exemples(nombre_exemples, mean)\n",
    "    for exemple in exemples:\n",
    "        the_set.addExample(exemple, choice(labels))\n",
    "        \n",
    "set_app = ls.LabeledSet(2)\n",
    "ajouter_exemples_aleatoires(set_app, 100, -2, [-1])\n",
    "ajouter_exemples_aleatoires(set_app, 100, 2, [1])\n",
    "\n",
    "set_test = ls.LabeledSet(2)\n",
    "ajouter_exemples_aleatoires(set_test, 200, -2.5, [-1])\n",
    "ajouter_exemples_aleatoires(set_test, 200, 2.5, [1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ClassifierPerceptronKernel(2,0.001,100,1)\n",
    "p.train(set_app)\n",
    "#Tester le modele\n",
    "ut.plot_frontiere(set_test,p)\n",
    "ut.plot2DSet(set_test)\n",
    "print(p.accuracy(set_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def createXOR(nb_points,var):\n",
    "    donnee_xor= ls.LabeledSet(2)\n",
    "    ajouter_exemples_aleatoires(donnee_xor, 100, [0,0], [1])\n",
    "    ajouter_exemples_aleatoires(donnee_xor, 100, [1,1], [1])\n",
    "    ajouter_exemples_aleatoires(donnee_xor, 100, [1,0], [-1])\n",
    "    ajouter_exemples_aleatoires(donnee_xor, 100, [0,1], [-1])\n",
    "    return donnee_xor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data):\n",
    "    ind=np.random.permutation(data.size())\n",
    "    data_app=ls.LabeledSet(2)\n",
    "    data_test=ls.LabeledSet(2)\n",
    "    for i in range (int(data.size()/2)):\n",
    "        data_app.addExample(data.getX(ind[i]),data.getY(ind[i]))\n",
    "    for j in range (i,data.size()):\n",
    "        data_test.addExample(data.getX(ind[j]),data.getY(ind[j]))\n",
    "    return data_app, data_test\n",
    "data_app, data_test = split(the_set)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generer_exemple(mean=0):\n",
    "    \"\"\"Genere un exemple\"\"\"\n",
    "    cov = [[0.001, 0.005], [0.006, 0.003]] # plus que la covariance soit petite, plus que les points soient centralisées\n",
    "    return np.random.multivariate_normal(mean, cov)\n",
    "\n",
    "def generer_exemples(nombre_exemples, mean=0):\n",
    "    \"\"\" Genere une liste de taille 'nombre_exemple' d'exemples \"\"\"\n",
    "    exemples = list()\n",
    "    for _ in range(nombre_exemples):\n",
    "        exemples.append(generer_exemple(mean))   \n",
    "    return exemples\n",
    "\n",
    "def ajouter_exemples_aleatoires(the_set, nombre_exemples, mean, labels):\n",
    "    \"\"\" Ajoute dans 'the_set' un total de 'nombre_exemples' exemples\n",
    "    associés aleatoirement à un label contenu dans 'labels'. \"\"\"\n",
    "    from random import choice\n",
    "    exemples = generer_exemples(nombre_exemples, mean)\n",
    "    for exemple in exemples:\n",
    "        the_set.addExample(exemple, choice(labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = ClassifierPerceptronKernel(2,0.001,100,1)\n",
    "c=createXOR(100,2)\n",
    "app,test=split(c)\n",
    "p.train(app)\n",
    "#Tester le modele\n",
    "ut.plot_frontiere(test,p)\n",
    "ut.plot2DSet(test)\n",
    "print(p.accuracy(test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Implémenter le kernel : $(x_1,x_2) \\rightarrow (1,x_1,x_2,x_1*x_1,x_2*x_2,x_1*x_2)$. Entrainer le perceptron correspondant sur le XOR. Que constatez-vous ? Donnez une explication (explication donnée en cours lors de la prochaine séance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KernelPoly:\n",
    "    def transform(self,x):\n",
    "        y=np.asarray([1,x[0],x[1],x[0]*x[0],x[1]*x[1],x[0]*x[1]])\n",
    "        return y\n",
    "        \n",
    "\n",
    "N=100\n",
    "k=KernelPoly()\n",
    "k.transform(the_set.getX(1))\n",
    "perceptron_k=ClassifierPerceptronKernel(6,0.001,100,k)\n",
    "\n",
    "##TESTER SUR XOR ET DESSINER LA FRONTIèRE DE DECISION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mise en oeuvre sur des données réelles \n",
    "-------\n",
    "A partir de datasets trouvés sur le web, réaliser un ensemble d'expérimentations permettant de comparer les 3 classifiers (knn, perceptron de Rosenblatt et version kernélisée) que vous avez implémentés.\n",
    "\n",
    "Par exemple, vous pouvez utiliser les datasets suivants:\n",
    "- https://archive.ics.uci.edu/ml/datasets/Breast+Cancer+Coimbra\n",
    "- https://www.kaggle.com/uciml/indian-liver-patient-records\n",
    "- voir sur les données ouvertes de Paris : https://opendata.paris.fr/explore/?sort=modified\n",
    "\n",
    "Afin d'utiliser de tels jeux de données, il sera certainement nécessaire que vous réalisiez un prétraitement afin de pouvoir utiliser vos implémentations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Préparation du projet\n",
    "\n",
    "Le projet est à rendre lors de la dernière séance de TD-TME de votre groupe qui aura lieu la semaine du **16 avril**. Lors de cette dernière séance, une soutenance sera organisée afin que vous présentiez le travail réalisé et les résultats obtenus.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Données\n",
    "\n",
    "Les données à utiliser sont des données issues d'une base de films et de notations faites par des spectateurs:\n",
    "- base MovieLens : https://grouplens.org/datasets/movielens/\n",
    "- base complémentaire `Movie Industrie`: https://www.kaggle.com/danielgrijalvas/movies\n",
    "\n",
    "\n",
    "<font color=\"RED\">**ATTENTION**: la base est très volumineuse (plus d'1Go) et ne pourra pas tenir sur votre répertoire de travail des machines de TME.</font>\n",
    "\n",
    "Dans un premier temps, vous travaillerez sur la version réduite de cette base (`ml-latest-small.zip` sur le site movilens) que vous pouvez récupérer sur les machines de TD-TME: `/users/Enseignants/marsala/3i026-2019/MovieLens-small.tgz`\n",
    "Cette version contient qu'une partie des lignes de la base originale.\n",
    "\n",
    "\n",
    "\n",
    "En salle de TD-TME, vous accéderez aux données dans les fichiers suivants (à ne pas recopier !):\n",
    "- répertoire : `/users/Enseignants/marsala/3i026-2019`\n",
    "- répertoire des données MovieLens version réduite : `/users/Enseignants/marsala/3i026-2019/MovieLens-small/` \n",
    "- fichier archive avec les données MovieLesns version réduite : `/users/Enseignants/marsala/3i026-2019/MovieLens-small.tgz`\n",
    "- répertoire des données MovieLens : `/users/Enseignants/marsala/3i026-2019/MovieLens/` \n",
    "  Il contient les fichiers CSV que vous pouvez ouvrir directement dans le notebook.\n",
    "- fichier `/users/Enseignants/marsala/3i026-2019/kaggle-movies.csv` : infos sur les films de la base Movie Industrie\n",
    "   \n",
    "   \n",
    "  \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"RED\" size=\"+1\">**[Q]**</font> Réaliser des expérimentations avec la base MovieLens version réduite.\n",
    "\n",
    "Charger les données dans un dataframe, afficher des informations statistiques sur les données, commencer à réfléchir comment appliquer les classifieurs vus dans les séances précédentes sur ces données..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
